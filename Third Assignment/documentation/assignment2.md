#### Indexer

The first step to use the searcher is to index one of the collections available, so we can perform searches over it.
The indexer is similar to the already implemented in the first assignment (we already counted the term frequency for each document). We tried to develop an index that was as much simple and general as possible (allowing it to be used by both TF-IDF and BM25), therefore, when the caches - ***cache in disk*** for BM25 and TF-IDF are set to `False` we just save the raw term frequencies so they can be used later (in search time) to rank the documents.

We also implemented a new structure called `DocumentInfo` that allowed us to store and retrieve information about the documents that were used in the searcher to normalize weights and rank the documents. This structure stores, for each document, its length - `document_lenght` - that will be used by BM25 and and its norm `document_norm` - that will be used by TF-IDF. The `DocumentsInfo` structure is also stored in disk, alongside with the index in a file called `document_info.json` inside the `<outputDir>/FinalIndex` directory.

To run the indexer for TF-IDF and BM25 with *cache in disk* off we do this command:

```bash
python3 main.py indexer collections/pubmed_2022_tiny.jsonl.gz pubmedSPIMIindex --tk.minL 2 --tk.stopwords stopwords.txt --tk.stemmer potterNLTK --indexer.memory_threshold 16 --r
eader.memory_threshold 8
```

**Note:** The command is the same for TF-IDF and BM25 as we generate a general index structure that can be used by both algorithms - storing extra data needed by searcher in the `DocumentsInfo`.

If we use *cache in disk* then, in addition to the general index, we will also create an additional index - which will be stored in `<outputDir>/FinalIndex/cached[0..].jsonl` - to store the data generated by the cache in memory process. This index will be loaded by the searcher and used instead of the general index, speeding up the search by almost 70% (results obtained while testing, manually, both processes, with cache and without cache for BM25).

To run the indexer for TF-IDF with *cache in disk* enabled we do this command:

```bash
python3 main.py indexer collections/pubmed_2022_tiny.jsonl.gz pubmedSPIMIindex --tk.minL 2 --tk.stopwords stopwords.txt --tk.stemmer potterNLTK --indexer.memory_threshold 16 --r
eader.memory_threshold 8 --indexer.tfidf.cache_in_disk
```

And for BM25:

```bash
python3 main.py indexer collections/pubmed_2022_tiny.jsonl.gz pubmedSPIMIindex --tk.minL 2 --tk.stopwords stopwords.txt --tk.stemmer potterNLTK --indexer.memory_threshold 16 --r
eader.memory_threshold 8 --indexer.bm25.cache_in_disk
```

For TF-IDF multiple SMART notations were implemented - we implemented:

* **l**,**a** and **n** for **term frequency** metric;
* **t**, **p** and **n** for **document frequency** metric;
* **c** and **n** for **normalization**.

#### Searcher

As for the searcher, it can use the general index and run over it (if no cache in disk parameter is defined), or, use the cache in disk speeding up the process.

If we use the general index, then additional calculations need to be done in search time making this process slower.

Two different "search strategies" were also implemented, the `batch_search` that will read a set of *queries* from a file and search results for those queries, and the interactive approach, that will keep asking the user for queries and presenting the results.

To run the searcher using the **batch mode** using BM25:

```bash
python3 main.py searcher pubmedSPIMIindex questions/questions.jsonl ranked ranking.bm25
```  

To run the searcher using the **interactive mode** using BM25:

```bash
python3 main.py searcher --interactive True pubmedSPIMIindex questions/questions.jsonl ranked ranking.bm25
```